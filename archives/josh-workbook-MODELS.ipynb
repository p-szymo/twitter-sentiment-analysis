{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import twint\n",
    "\n",
    "# Fixes runtime errors with twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_style('ticks')\n",
    "\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('Datasets/features_df.pkl', 'rb') as handle:\n",
    "    features_df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>...</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>lda_1</th>\n",
       "      <th>lda_2</th>\n",
       "      <th>lda_3</th>\n",
       "      <th>lda_4</th>\n",
       "      <th>lda_5</th>\n",
       "      <th>lda_6</th>\n",
       "      <th>lda_7</th>\n",
       "      <th>lda_8</th>\n",
       "      <th>lda_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212523e+18</td>\n",
       "      <td>1.212523e+18</td>\n",
       "      <td>1.577923e+12</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>https://mltshp.com/p/1HLSB¬† \"This is the death mask of Thomas, an unknown peasant that died in a river.\"</td>\n",
       "      <td>[]</td>\n",
       "      <td>8.431951e+17</td>\n",
       "      <td>Best_of_MLTSHP</td>\n",
       "      <td>MLTSHP</td>\n",
       "      <td>https://twitter.com/Best_of_MLTSHP/status/1212523477896294400</td>\n",
       "      <td>...</td>\n",
       "      <td>death thomas unknown peasant died river</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.212518e+18</td>\n",
       "      <td>1.212518e+18</td>\n",
       "      <td>1.577922e+12</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Ready to heard this? Homemade hair treatment and ann cherry dead sea mud mask... Fucking putas swear they are more woman than me.... Bitch shut th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.044739e+18</td>\n",
       "      <td>lumora_lu</td>\n",
       "      <td>MiLu</td>\n",
       "      <td>https://twitter.com/lumora_lu/status/1212518043353530368</td>\n",
       "      <td>...</td>\n",
       "      <td>ready heard homemade hair treatment ann cherry dead sea mud fucking putas swear woman bitch shut fuck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.212518e+18</td>\n",
       "      <td>1.212518e+18</td>\n",
       "      <td>1.577922e+12</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>We all know what a joke #CCPChina is when it comes to epidemic outbreak,think of how they stayed silent about #SARS.\\nDear world,stay away from #H...</td>\n",
       "      <td>['#ccpchina', '#sars', '#hk', '#hkers']</td>\n",
       "      <td>9.630325e+17</td>\n",
       "      <td>odiecher</td>\n",
       "      <td>odiecher</td>\n",
       "      <td>https://twitter.com/odiecher/status/1212517557690748928</td>\n",
       "      <td>...</td>\n",
       "      <td>joke #ccpchina come epidemic outbreakthink stayed silent #sars dear worldstay away #hk im sure infected amongst already dear fellow #hkers facewit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.212516e+18</td>\n",
       "      <td>1.200523e+18</td>\n",
       "      <td>1.577921e+12</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Thought death masks gave you the horn freak</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.819219e+09</td>\n",
       "      <td>Hevysmoker</td>\n",
       "      <td>Ashley Collins</td>\n",
       "      <td>https://twitter.com/Hevysmoker/status/1212515585562726401</td>\n",
       "      <td>...</td>\n",
       "      <td>thought death gave horn freak</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.212510e+18</td>\n",
       "      <td>1.212391e+18</td>\n",
       "      <td>1.577920e+12</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Interesting cult of death mask he‚Äôs wearing, ü§î\\nelectronically posing as he did as of the CIA while Brennan was Chief. üßê</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.361956e+08</td>\n",
       "      <td>FaithR8s</td>\n",
       "      <td>‚ùåPatriot Fanüá∫üá∏üóΩ‚òïÔ∏èüé∂‚ùå</td>\n",
       "      <td>https://twitter.com/FaithR8s/status/1212510409858670593</td>\n",
       "      <td>...</td>\n",
       "      <td>interesting cult death thinkingface electronically posing cia brennan chief facewithmonocle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  conversation_id    created_at        date  \\\n",
       "0  1.212523e+18     1.212523e+18  1.577923e+12  2020-01-01   \n",
       "1  1.212518e+18     1.212518e+18  1.577922e+12  2020-01-01   \n",
       "2  1.212518e+18     1.212518e+18  1.577922e+12  2020-01-01   \n",
       "3  1.212516e+18     1.200523e+18  1.577921e+12  2020-01-01   \n",
       "4  1.212510e+18     1.212391e+18  1.577920e+12  2020-01-01   \n",
       "\n",
       "                                                                                                                                                   tweet  \\\n",
       "0                                               https://mltshp.com/p/1HLSB¬† \"This is the death mask of Thomas, an unknown peasant that died in a river.\"   \n",
       "1  Ready to heard this? Homemade hair treatment and ann cherry dead sea mud mask... Fucking putas swear they are more woman than me.... Bitch shut th...   \n",
       "2  We all know what a joke #CCPChina is when it comes to epidemic outbreak,think of how they stayed silent about #SARS.\\nDear world,stay away from #H...   \n",
       "3                                                                                                            Thought death masks gave you the horn freak   \n",
       "4                               Interesting cult of death mask he‚Äôs wearing, ü§î\\nelectronically posing as he did as of the CIA while Brennan was Chief. üßê   \n",
       "\n",
       "                                  hashtags       user_id        username  \\\n",
       "0                                       []  8.431951e+17  Best_of_MLTSHP   \n",
       "1                                       []  1.044739e+18       lumora_lu   \n",
       "2  ['#ccpchina', '#sars', '#hk', '#hkers']  9.630325e+17        odiecher   \n",
       "3                                       []  2.819219e+09      Hevysmoker   \n",
       "4                                       []  2.361956e+08        FaithR8s   \n",
       "\n",
       "                  name  \\\n",
       "0               MLTSHP   \n",
       "1                 MiLu   \n",
       "2             odiecher   \n",
       "3       Ashley Collins   \n",
       "4  ‚ùåPatriot Fanüá∫üá∏üóΩ‚òïÔ∏èüé∂‚ùå   \n",
       "\n",
       "                                                            link  ...  \\\n",
       "0  https://twitter.com/Best_of_MLTSHP/status/1212523477896294400  ...   \n",
       "1       https://twitter.com/lumora_lu/status/1212518043353530368  ...   \n",
       "2        https://twitter.com/odiecher/status/1212517557690748928  ...   \n",
       "3      https://twitter.com/Hevysmoker/status/1212515585562726401  ...   \n",
       "4        https://twitter.com/FaithR8s/status/1212510409858670593  ...   \n",
       "\n",
       "                                                                                                                                            clean_tweets  \\\n",
       "0                                                                                                                death thomas unknown peasant died river   \n",
       "1                                                  ready heard homemade hair treatment ann cherry dead sea mud fucking putas swear woman bitch shut fuck   \n",
       "2  joke #ccpchina come epidemic outbreakthink stayed silent #sars dear worldstay away #hk im sure infected amongst already dear fellow #hkers facewit...   \n",
       "3                                                                                                                          thought death gave horn freak   \n",
       "4                                                            interesting cult death thinkingface electronically posing cia brennan chief facewithmonocle   \n",
       "\n",
       "   lda_1  lda_2  lda_3 lda_4  lda_5 lda_6  lda_7 lda_8 lda_9  \n",
       "0      0      0      0     0      0     1      0     0     0  \n",
       "1      0      0      0     0      1     0      0     0     0  \n",
       "2      1      0      0     0      0     0      0     0     0  \n",
       "3      0      0      0     0      0     0      0     1     0  \n",
       "4      0      0      0     0      0     0      0     1     0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/5k_tweets_lda_10.csv', index_col=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, df.sentiment, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use padding or truncation to make each observation have 400 features\n",
    "train_features = sequence.pad_sequences(X_train_scaled, maxlen=1000, dtype='float64', truncating='post')\n",
    "test_features = sequence.pad_sequences(X_test_scaled, maxlen=1000, dtype='float64', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.55      , 0.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.25      , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first observation\n",
    "test_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = Sequential()\n",
    "\n",
    "# Add an embedding layer\n",
    "network.add(layers.Embedding(input_dim=X_train.shape[1], output_dim=128))\n",
    "\n",
    "# Add a long short-term memory layer with 128 units\n",
    "network.add(layers.LSTM(units=128))\n",
    "\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(layers.Dense(units=1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                optimizer='Adam', # Adam optimization\n",
    "                metrics=['accuracy']) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36702     negative\n",
       "268432    positive\n",
       "474540     neutral\n",
       "347524    negative\n",
       "562666    negative\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    y_train == 'negative',\n",
    "    y_train == 'neutral'\n",
    "]\n",
    "\n",
    "choices = [0,1]\n",
    "\n",
    "conditions_test = [\n",
    "    y_test == 'negative',\n",
    "    y_test == 'neutral'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_num = pd.DataFrame(np.select(conditions, choices, 2))\n",
    "y_train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_num = pd.DataFrame(np.select(conditions_test, choices, 2))\n",
    "y_test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "history = network.fit(train_features, # Features\n",
    "                      y_train_num, # Target\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=1, \n",
    "                      batch_size=50000, # Number of observations per batch\n",
    "                      validation_data=(test_features, y_test_num)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomek/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tomek = TomekLinks()\n",
    "X_res, y_res = tomek.fit_resample(X_train_scaled, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "forest_res = RandomForestClassifier(\n",
    "                                        class_weight='balanced',\n",
    "                                        random_state=1, n_jobs=-1,\n",
    "                                        n_estimators=50, max_depth=2)\n",
    "\n",
    "# fit training data\n",
    "forest_res.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict test dta\n",
    "y_pred_forest = forest_res.predict(X_test_scaled)\n",
    "\n",
    "# check accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, y_pred_forest))\n",
    "# check f1\n",
    "print('Test F1 score: ', f1_score(y_test, y_pred_forest, average='weighted'))\n",
    "# check recall\n",
    "print('Test Recall score: ', recall_score(y_test, y_pred_forest, average='weighted'))\n",
    "# check precision\n",
    "print('Test Precision score: ', precision_score(y_test, y_pred_forest, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAP HEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Using', 'VBG'), ('the', 'DT'), ('coverage', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('yellow', 'JJ'), ('card', 'NN'), ('to', 'TO'), ('mask', 'VB'), ('the', 'DT'), ('fact', 'NN'), ('his', 'PRP$'), ('team', 'NN'), ('lost', 'VBD'), ('to', 'TO'), ('Southampton', 'NNP'), ('ClassicJose', 'NNP'), ('CoverUp', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "pos = TextBlob(tweets[2])\n",
    "print(pos.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('masks', 'NNS')\n"
     ]
    }
   ],
   "source": [
    "for tag in pos.tags:\n",
    "    if 'mask' in tag[0]:\n",
    "        print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.My', 'NN'), ('daughter', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('sick', 'VBN'), ('with', 'IN'), ('a', 'DT'), ('nasty', 'JJ'), ('cough', 'NN'), ('for', 'IN'), ('weeks', 'NNS'), ('She', 'PRP'), ('ignores', 'VBZ'), ('my', 'PRP$'), ('advice', 'NN'), ('about', 'IN'), ('wearing', 'VBG'), ('a', 'DT'), ('mask', 'NN'), ('Can', 'NNP'), ('any', 'DT'), ('Drs', 'NNP'), ('out', 'IN'), ('there', 'RB'), ('please', 'VB'), ('tweet', 'NN'), ('about', 'IN'), ('the', 'DT'), ('health', 'NN'), ('impacts', 'NNS'), ('of', 'IN'), ('breathing', 'VBG'), ('this', 'DT'), ('toxic', 'NN'), ('air', 'NN'), ('even', 'RB'), ('when', 'WRB'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('not', 'RB'), ('smelling', 'JJ'), ('strongly', 'RB'), ('of', 'IN'), ('smoke', 'NN'), ('so', 'IN'), ('that', 'IN'), ('I', 'PRP'), ('can', 'MD'), ('show', 'VB'), ('her', 'PRP$'), ('I', 'PRP'), ('am', 'VBP'), ('not', 'RB'), ('full', 'JJ'), ('of', 'IN'), ('shit', 'NN')]\n",
      "[('üò∫‚úè', 'NN'), ('‚Äî', 'NNP'), ('Aside', 'NNP'), ('from', 'IN'), ('butt', 'NN'), ('masks', 'NNS'), ('yes', 'UH'), ('those', 'DT'), ('exist', 'VBP'), ('I', 'PRP'), ('found', 'VBD'), ('out', 'RB'), ('recently', 'RB'), ('and', 'CC'), ('lotions', 'NNS'), ('and', 'CC'), ('so', 'RB'), ('forth', 'JJ'), ('to', 'TO'), ('condition', 'VB'), ('the', 'DT'), ('skin', 'NN'), ('here', 'RB'), (\"'s\", 'POS'), ('my', 'PRP$'), ('1‚Ä¶', 'CD'), ('https', 'NN'), ('//curiouscat.me/EricaLScott/post/1038934596', 'NN'), ('t=1577923159', 'NN'), ('‚Ä¶', 'NN')]\n",
      "[('y', 'NN'), ('‚Äô', 'VBZ'), ('all', 'DT'), ('her', 'PRP$'), ('energy', 'NN'), ('is', 'VBZ'), ('something', 'NN'), ('ELSE', 'RB'), ('y', 'JJ'), ('‚Äô', 'NNP'), ('all', 'DT'), ('post', 'NN'), ('4', 'CD'), ('pics', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('generic', 'JJ'), ('lookin', 'JJ'), ('ass', 'NN'), ('white', 'JJ'), ('skinny', 'JJ'), ('girl', 'NN'), ('eating', 'VBG'), ('a', 'DT'), ('tomato', 'NN'), ('w', 'NN'), ('a', 'DT'), ('face', 'NN'), ('mask', 'NN'), ('on', 'IN')]\n",
      "[('We', 'PRP'), ('all', 'DT'), ('have', 'VBP'), ('some', 'DT'), ('kind', 'NN'), ('of', 'IN'), ('mask', 'NN'), ('Just', 'RB'), ('how', 'WRB'), ('much', 'JJ'), ('of', 'IN'), ('one', 'CD'), ('That', 'DT'), ('‚Äô', 'VBP'), ('s', 'JJ'), ('different', 'JJ'), ('for', 'IN'), ('each', 'DT'), ('of', 'IN'), ('us', 'PRP'), ('pic.twitter.com/BkoMZ98rlo', 'NN')]\n",
      "[('The', 'DT'), ('market', 'NN'), ('has', 'VBZ'), ('moved', 'VBN'), ('on', 'IN'), ('Was', 'NNP'), ('given', 'VBN'), ('a', 'DT'), ('detox', 'JJ'), ('scalp', 'NN'), ('mask', 'NN'), ('And', 'CC'), ('since', 'IN'), ('it', 'PRP'), ('promised', 'VBD'), ('deep', 'JJ'), ('action', 'NN'), ('I', 'PRP'), ('can', 'MD'), ('only', 'RB'), ('assume', 'VB'), ('that', 'IN'), ('the', 'DT'), ('giver', 'NN'), ('wanted', 'VBD'), ('to', 'TO'), ('imply', 'VB'), ('that', 'IN'), ('my', 'PRP$'), ('brain', 'NN'), ('needs', 'VBZ'), ('a', 'DT'), ('detox', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets[5:10]:\n",
    "    pos = TextBlob(tweet)\n",
    "    print(pos.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hand', 40134),\n",
       " ('need', 39383),\n",
       " ('spread', 33418),\n",
       " ('protect', 32088),\n",
       " ('make', 31605),\n",
       " ('help', 30306),\n",
       " ('say', 28477),\n",
       " ('glove', 27649),\n",
       " ('public', 25717),\n",
       " ('hospital', 25525),\n",
       " ('new', 25340),\n",
       " ('time', 25085),\n",
       " ('medical', 24652),\n",
       " ('china', 24641),\n",
       " ('doctor', 24152),\n",
       " ('home', 23986),\n",
       " ('work', 23382),\n",
       " ('day', 22567),\n",
       " ('stop', 21958),\n",
       " ('trump', 21074),\n",
       " ('infected', 21008),\n",
       " ('please', 20635),\n",
       " ('everyone', 20359),\n",
       " ('health', 20312),\n",
       " ('death', 20287)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(words).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
